{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets.flowers102 as flowers102\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as scp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import skimage.io as skio\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 102])\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network Model Class\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_channels=3, num_out_ch=[8,16], img_w=100, img_h=100, num_classes=102):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0], \n",
    "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1], \n",
    "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(in_features = int(img_w/4)*int(img_h/4)*num_out_ch[1], out_features=num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.fc(x.reshape(x.shape[0], -1))\n",
    "\n",
    "        return x\n",
    "\n",
    "model = MyCNN()\n",
    "x = torch.randn(32, 3, 100, 100)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters Global\n",
    "NUM_OUT_CH = [8, 16]\n",
    "IMAGE_W = 200\n",
    "IMAGE_H = 200\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 7\n",
    "# Learning rate\n",
    "LR = 0.001\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# model\n",
    "model = MyCNN(num_channels=3, num_out_ch=NUM_OUT_CH, img_w=IMAGE_W, img_h=IMAGE_H, num_classes=102)\n",
    "model = model.to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr = LR)\n",
    "\n",
    "# Loss Function\n",
    "# Minimise inacuracies of model\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = flowers102.Flowers102(root=\".\", download=True)\n",
    "data_path = 'flowers-102/jpg'\n",
    "label_path = 'flowers-102/imagelabels.mat'\n",
    "label_arr = scp.loadmat(label_path)['labels']\n",
    "# Make the label pythonic as indexing starts at 0\n",
    "label_arr -= 1\n",
    "#Images\n",
    "# sorted(os.listdir(data_path))[0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=4, figsize=(8,6))\n",
    "image_num = random.sample(range(1, 8190), 8)\n",
    "#rows\n",
    "for i in range(2):\n",
    "    #cols\n",
    "    for j in range(4):\n",
    "        image = skio.imread(os.path.join(data_path, f'image_{image_num[i*4+j]:05}.jpg'))\n",
    "        ax[i, j].imshow(image)\n",
    "        ax[i, j].axis('off')\n",
    "        ax[i, j].set_title(f'label = {label_arr[0, image_num[i*4+j]]}')\n",
    "\n",
    "# data frame: index: 8189; column: 'path', 'label'\n",
    "labels_list = list(label_arr[0, :])\n",
    "image_path_list = sorted(glob.glob(os.path.join(data_path, '*.jpg')))\n",
    "metadata = pd.DataFrame(\n",
    "    {'image_path': image_path_list,\n",
    "     'image_label': labels_list}\n",
    ")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyFlowerDataset(Dataset):\n",
    "    def __init__(self, metadata, transform=None):\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "    # Understand how many images we have in data set\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    # Returns an image and a label for a given index\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.metadata.iloc[idx, 0]\n",
    "        image = skio.imread(image_path)\n",
    "        label = torch.tensor(int(self.metadata.iloc[idx, 1]))\n",
    "        label = F.one_hot(label, num_classes=102)\n",
    "        label = label.float()\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return (image, label)\n",
    "    \n",
    "# Images must have same dimension by scaling which has downsides of making some images not look like they normall do but upside we don't lose any inforrmation\n",
    "# Alternative could be to use cropping which has ups and downs too but overall seems that scaling might be best option\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(), \n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomCrop(50),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((IMAGE_W, IMAGE_H)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.299, 0.244, 0.255))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(), \n",
    "    transforms.Resize((IMAGE_W, IMAGE_H)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.299, 0.244, 0.255))\n",
    "])\n",
    "\n",
    "dataset = MyFlowerDataset(metadata, transform=None)\n",
    "\n",
    "# Normally more images for training EXPERIMENT with this\n",
    "train_set, test_set, _ = torch.utils.data.random_split(dataset, [1020, 6149, 1020])\n",
    "train_set.dataset.transform = train_transform\n",
    "test_set.dataset.transform = test_transform\n",
    "\n",
    "# defining the dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    x = x.to(device)\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=4, figsize=(12, 8))\n",
    "    for i in range(2):\n",
    "        for j in range(4):\n",
    "            # First 8 images\n",
    "            ax[i, j].imshow(x[i*4+j].cpu().permute(1, 2, 0))\n",
    "            ax[i, j].axis(\"off\")\n",
    "    break\n",
    "# Images are in \"transform\" format\n",
    "    # 1) ToPilImages\n",
    "    # 2)  Tensore\n",
    "    # 3) Rescaled\n",
    "    # 4) Normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_corrects = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            # sending the data to the device\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # preparing the data for the model\n",
    "            #N/A\n",
    "\n",
    "            # forward\n",
    "            y_hat = model(x)\n",
    "\n",
    "            # calculate ACCURACY\n",
    "            _, labels = y.max(1)\n",
    "            _, predictions = y_hat.max(1)\n",
    "            num_corrects += (predictions == labels).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(f'Accuracy: {num_corrects}/{num_samples}: {num_corrects/num_samples * 100:.2f}')\n",
    "        model.train()\n",
    "    \n",
    "# Training loop\n",
    "#for epoch in range(NUM_EPOCHS):\n",
    "#    running_loss = 0\n",
    "#    # Index of mini batch NOT image\n",
    "#    for index, (x, y) in enumerate(train_loader):\n",
    "#        # Send the data to the device\n",
    "#        # Both x, y are pytorch tensors\n",
    "#        x = x.to(device)\n",
    "#        y  = y.to(device)\n",
    "#        \n",
    "#        # Prepare the data\n",
    "#        # N/A\n",
    "#\n",
    "#        # Forward  Propogation\n",
    "#        y_hat = model(x)\n",
    "#        loss = criterion(y_hat, y)\n",
    "#        running_loss += loss\n",
    "#        \n",
    "#        # Backward Propogation\n",
    "#        # Number of images in each mini-batch can effect the efficiency \n",
    "#        optimizer.zero_grad()\n",
    "#        loss.backward()\n",
    "#        optimizer.step()\n",
    "#        \n",
    "#    print(f'Epoch {epoch}: loss: {running_loss} ')\n",
    "#    check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to improve\n",
    "# Once training doesn't improve with more epochs, gotta stop training (as you might over fit model)\n",
    "# Regularisation - get trained even more and not let accuracy plateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ACCURACY_EVERY = 50\n",
    "\n",
    "# Progress bar\n",
    "# Training loop\n",
    "count = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0\n",
    "    with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
    "        # Index of mini batch NOT image\n",
    "        for index, (x, y) in enumerate(tepoch):\n",
    "            # Send the data to the device\n",
    "            # Both x, y are pytorch tensors\n",
    "            x = x.to(device)\n",
    "            y  = y.to(device)\n",
    "            \n",
    "            # Prepare the data\n",
    "            # N/A\n",
    "\n",
    "            # Forward  Propogation\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            running_loss += loss\n",
    "            \n",
    "            # Backward Propogation\n",
    "            # Number of images in each mini-batch can effect the efficiency \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "        \n",
    "        print(f'Epoch {epoch}: loss: {running_loss} ')\n",
    "        if count == 0:\n",
    "            check_accuracy(test_loader, model)\n",
    "        count = (count + 1) % ACCURACY_EVERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
